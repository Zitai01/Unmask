<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>GPU Scheduling for AI &mdash; In-Game Inferencing SDK 1.0.0 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/pygments_dark.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/theme-switcher-general.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/omni-style-dark.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/api-styles-dark.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/omni-style.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/api-styles.css" type="text/css" />
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/mermaid-init.js"></script>
        <script src="../../_static/clipboard.min.js"></script>
        <script src="../../_static/copybutton.js"></script>
        <script src="../../_static/theme-setter.js"></script>
        <script src="../../_static/design-tabs.js"></script>
        <script src="../../_static/version.js"></script>
        <script src="../../_static/social-media.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="NVIGI - Programming Guide" href="ProgrammingGuide.html" />
    <link rel="prev" title="Architecture" href="Architecture.html" />
 


</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >


<a href="../../index.html">
  <img src="../../_static/nvidia-logo-white.png" class="logo" alt="Logo"/>
</a>

<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../NVIGIDeveloperPack.html">NVIDIA In-Game Inferencing (NVIGI) Developer Pack 1.1.0 Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sample/README.html">NVIGI 3D Sample</a></li>
<li class="toctree-l1"><a class="reference internal" href="Architecture.html">Architecture</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">GPU Scheduling for AI</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#supported-plugins">Supported plugins</a></li>
<li class="toctree-l2"><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="#a-note-on-performance-measurement">A note on performance measurement</a></li>
<li class="toctree-l2"><a class="reference internal" href="#how-to-use">How to use</a></li>
<li class="toctree-l2"><a class="reference internal" href="#how-to-set-the-relative-priority-of-compute-and-graphics">How to set the relative priority of compute and graphics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#api">API</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#cig-and-d3d-wrappers-e-g-streamline">CiG and D3D Wrappers (e.g. Streamline)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#limitations">Limitations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#unrealengine-5-example-code">UnrealEngine 5 example code</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ProgrammingGuide.html">NVIGI - Programming Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="ProgrammingGuideAI.html">NVIGI - Programming Guide For Local And Cloud Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../plugins/sdk/README.html">NVIDIA In-Game Inference AI Plugins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../plugins/sdk/docs/ProgrammingGuideASRWhisper.html">Automatic Speech Recognition (ASR) - Whisper Programming Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../plugins/sdk/docs/ProgrammingGuideGPT.html">Generative Pre-Trained Transformers (GPT) Programming Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../plugins/sdk/docs/ProgrammingGuideEmbed.html">Embedding (EMBED) Programming Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../source-build/README.html">NVIGI Public Source GitHub Pull-and-Build Scripts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../plugins/sdk/docs/CustomizingPlugins.html">Creating a Customized Plugin</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../plugins/sdk/3rd-party-licenses.html">3rd PARTY SOFTWARE</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">In-Game Inferencing SDK</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">


<li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
  
<li>GPU Scheduling for AI</li>

      <li class="wy-breadcrumbs-aside">
      </li>
<li class="wy-breadcrumbs-aside">

  <span>&nbsp;</span>
</li>

  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="gpu-scheduling-for-ai">
<h1>GPU Scheduling for AI<a class="headerlink" href="#gpu-scheduling-for-ai" title="Permalink to this headline"></a></h1>
<p>Games typically optimize graphics to maximize GPU utilization, so when you add AI compute to a game it is essential to configure the GPU scheduler to minimize the effect on the game’s frame rate. This document describes how to do this.</p>
<section id="supported-plugins">
<h2>Supported plugins<a class="headerlink" href="#supported-plugins" title="Permalink to this headline"></a></h2>
<p>Optimized GPU scheduling is currently utilized by the following CUDA plugins.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">plugins/sdk</span></code> in current SDK</p>
<ul>
<li><p>Automatic Speech Recognition (<code class="docutils literal notranslate"><span class="pre">nvigi::plugin::asr::ggml::cuda</span></code>)</p></li>
<li><p>Embed (<code class="docutils literal notranslate"><span class="pre">nvigi::plugin::embed::ggml::cuda</span></code>)</p></li>
<li><p>Generative Pre-Trained Transformer (<code class="docutils literal notranslate"><span class="pre">nvigi::plugin::gpt::ggml::cuda</span></code>)</p></li>
</ul>
</li>
<li><p>ACE SDK plugins - not available in all packs</p>
<ul>
<li><p>Audio To Emotion (<code class="docutils literal notranslate"><span class="pre">nvigi::plugin::a2e::trt::cuda</span></code>)</p></li>
<li><p>Audio To Face (<code class="docutils literal notranslate"><span class="pre">nvigi::plugin::a2f::trt::cuda</span></code>)</p></li>
<li><p>Audio To X Pipeline (<code class="docutils literal notranslate"><span class="pre">nvigi::plugin::a2x::pipeline</span></code>)</p></li>
</ul>
</li>
</ul>
</section>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this headline"></a></h2>
<p>NVIGI’s GPU scheduling uses CUDA in Graphics (CIG) which has the following requirements.</p>
<ul class="simple">
<li><p>NVIDIA display driver 555.85 or higher. 575.00 or higher is required to be able to set the relative priority of compute and graphics.</p></li>
<li><p>Hardware scheduling must be enabled in Windows 10 and 11. Windows 11 has hardware scheduling enabled by default.</p></li>
</ul>
</section>
<section id="a-note-on-performance-measurement">
<h2>A note on performance measurement<a class="headerlink" href="#a-note-on-performance-measurement" title="Permalink to this headline"></a></h2>
<p>It is important not to use GPU begin/end event queries (such as D3D12_QUERY_TYPE_TIMESTAMP or CUDA events) to measure the cost of AI features. The reason is that such measurements do not take into account how much graphics work is running in parallel with the AI compute during the measured interval. For example, if AI is using 10% of the execution units of the GPU for 1ms, and graphics is running in parallel using the other 90%, then queries would report the AI cost as 1ms, which is not correct. Instead its better to add a way to toggle the AI feature (for example a command line parameter), run a benchmark twice with the feature enabled and disabled, and report the difference in total frame time.</p>
</section>
<section id="how-to-use">
<h2>How to use<a class="headerlink" href="#how-to-use" title="Permalink to this headline"></a></h2>
<p>In order to schedule graphics and compute efficiently, NVIGI needs to know the D3D direct queue that your game is using for graphics. To do this, fill in a D3D12Parameters struct and chain it to the parameters of all NVIGI instances that you create. The following example shows how to do this for the ASR plugin.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>nvigi::ASRCreationParameters asrParams{};
asrParams.common = &amp;common;
asrParams.common-&gt;numThreads = myNumCPUThreads;
asrParams.common-&gt;vramBudgetMB = myVRAMBudget;
&lt;etc&gt;

D3D12Parameters d3d12Parameters{};
d3d12Parameters.queue = myGraphicsQueue;

// Tell ASR to run in parallel with graphics
if(NVIGI_FAILED(asrParams.chain(d3d12Parameters)))
{
    // Handle error
}

iasr-&gt;createInstance(asrParams, &amp;asrInstance);
</pre></div>
</div>
<p>This ensures that compute work submitted by NVIGI will run efficiently with graphics running in parallel.</p>
</section>
<section id="how-to-set-the-relative-priority-of-compute-and-graphics">
<h2>How to set the relative priority of compute and graphics<a class="headerlink" href="#how-to-set-the-relative-priority-of-compute-and-graphics" title="Permalink to this headline"></a></h2>
<p>In the past GPU compute workloads in games were often directly coupled to graphics frame generation, for example raytracing and animation. In contrast, NVIGI pipelines, consisting of automatic speech recognition (ASR), language models (LM) etc. can run asynchronously to frame generation. Their latency requirements are dictated not by human visual perception (measured in milliseconds), but how fast humans listen, think and speak (measured in hundreds of milliseconds). Each invocation of the pipeline (for example to process a question) can run across many graphics frames. For this reason the workload can be thought of as floating relative to the game’s graphics and compute workload.</p>
<p>For past compute workloads coupled to graphics generation, the compute work was often on the critical path of the graphics frame, and so the hardware executed compute with high priority to try to maximize graphics frame rate.</p>
<p>As NVIGI pipelines run independently to graphics generation we now have two variables we might want to optimize, graphics frame rate, and AI inference latency (and throughput). As the rate at which an unloaded GPU can produce AI tokens can be many times higher than a human’s ability to listen to and understand them, it often doesn’t make sense to run AI at maximum rate at the expense of graphics frame rate.</p>
<p>However, different game situations have different needs, and they might change at runtime. For example, a player might want snappy interaction with an NPC between quests (where graphics load might be light), but maximum FPS during gameplay. For this reason, NVIGI exposes the following three GPU scheduling modes:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">SchedulingMode::kPrioritizeGraphics</span></code> - try to maximize game FPS</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SchedulingMode::kPrioritizeCompute</span></code> - try to minimize AI inference latency</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SchedulingMode::kBalance</span></code> - balance scheduling between graphics and compute</p></li>
</ul>
<p>The default scheduling mode in NVIGI is kBalance. The default in normal CUDA usage is kPrioritizeCompute. Note that these modes are hints to the GPU scheduling hardware. Results may vary according to workload composition and GPU type.</p>
<p>These settings are currently supported by the following CUDA plugins:</p>
<ul class="simple">
<li><p>Automatic Speech Recognition (<code class="docutils literal notranslate"><span class="pre">nvigi::plugin::asr::ggml::cuda</span></code>)</p></li>
<li><p>Generative Pre-Trained Transformer (<code class="docutils literal notranslate"><span class="pre">nvigi::plugin::gpt::ggml::cuda</span></code>)</p></li>
</ul>
<section id="api">
<h3>API<a class="headerlink" href="#api" title="Permalink to this headline"></a></h3>
<p>You can set the priority at any time using SetGpuInferenceSchedulingMode(). The evaluate() call of supported plugins applies the priority to all CUDA kernels it launches, and those kernels may execute after evaluate() returns. The following example shows a game that has two phases, the first is before gameplay starts, and prioritizes NPC responsiveness, the second prioritizes FPS during gameplay.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>nvigi::IHWICommon* ihwiCommon{};
nvigiGetInterfaceDynamic(plugin::hwi::common::kId, &amp;ihwiCommon,nvigiLoadInterface);

ihwiCommon-&gt;SetGpuInferenceSchedulingMode(SchedulingMode::kPrioritizeCompute);
// evaluate() calls for pre-quest NPC interaction go here

ihwiCommon-&gt;SetGpuInferenceSchedulingMode(SchedulingMode::kPrioritizeGraphics);
// evaluate() calls for high FPS quest gameplay go here
</pre></div>
</div>
</section>
</section>
<section id="cig-and-d3d-wrappers-e-g-streamline">
<h2>CiG and D3D Wrappers (e.g. Streamline)<a class="headerlink" href="#cig-and-d3d-wrappers-e-g-streamline" title="Permalink to this headline"></a></h2>
<p>Care should be taken when integrating NVIGI into an existing application that is also using a D3D object wrapper like Streamline.  The queue/device parameters passed to NVIGI must be the <strong>native</strong> objects, not the app-level wrappers.  In the case of Streamline, this means using <code class="docutils literal notranslate"><span class="pre">slGetNativeInterface</span></code> to retrieve the base interface object before passing it to NVIGI.</p>
<section id="limitations">
<h3>Limitations<a class="headerlink" href="#limitations" title="Permalink to this headline"></a></h3>
<p>Note that CUDA Compute In Graphics contexts are not compatible with compute-only CUDA contexts. In particular, accessing CUDA pointers outside of the CUDA context that created them may cause CUDA API errors, which if not handled can causes crashes. So using multiple CUDA contexts in a game is not recommended. CUDA virtual memory and cudaMallocAsync are also not supported.</p>
</section>
</section>
<section id="unrealengine-5-example-code">
<h2>UnrealEngine 5 example code<a class="headerlink" href="#unrealengine-5-example-code" title="Permalink to this headline"></a></h2>
<p>The following example shows how to initialize NVIGI’s GPU scheduling in UnrealEngine5 (UE5). It uses UE5’s global dynamic RHI to get the D3D device and command queue that the game uses for graphics.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>// UE5 specific code
#include &quot;ID3D12DynamicRHI.h&quot; // For GDynamicRHI
ID3D12DynamicRHI* RHI = nullptr;
if (GDynamicRHI &amp;&amp; 
    GDynamicRHI-&gt;GetInterfaceType()==ERHIInterfaceType::D3D12)
{
    RHI = static_cast&lt;ID3D12DynamicRHI*&gt;(GDynamicRHI);
}
ID3D12CommandQueue* CmdQ = nullptr;
ID3D12Device* D3D12Device = nullptr;
if (RHI)
{
    CmdQ = RHI-&gt;RHIGetCommandQueue();
    int DeviceIndex = 0;
    D3D12Device = RHI-&gt;RHIGetDevice(DeviceIndex);
}
// Engine-independent code
nvigi::D3D12Parameters d3d12Params;
d3d12Params.device = D3D12Device;
d3d12Params.queue = CmdQ;

// Code to chain the d3d12Parameters to each NVIGI instance&#39;s parameters goes here
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
<img src="../../_static/NVIDIA-LogoBlack.svg" class="only-light"/>
<img src="../../_static/NVIDIA-LogoWhite.svg" class="only-dark"/>

<p class="notices">
<a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">Privacy Policy</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/" target="_blank">Manage My Privacy</a>
|
<a href="https://www.nvidia.com/en-us/preferences/start/" target="_blank">Do Not Sell or Share My Data</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank">Terms of Service</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">Accessibility</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank">Corporate Policies</a>
|
<a href="https://www.nvidia.com/en-us/product-security/" target="_blank">Product Security</a>
|
<a href="https://www.nvidia.com/en-us/contact/" target="_blank">Contact</a>
</p>

<p>
  Copyright &#169; 2024-2025, NVIDIA Corporation.
</p>

    <p>
      <span class="lastupdated">Last updated on Mar 13, 2025.
      </span></p>

  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
  </script>
 



</body>
</html>